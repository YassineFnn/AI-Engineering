{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://cognitiveclass.ai\"><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0101EN-SkillsNetwork/images/IDSN-logo.png\" width=\"400\"> </a>\n",
    "\n",
    "# Transformers with Keras\n",
    "\n",
    "Estimated time needed **45** mins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will learn how to use the Keras library to build a transformer using a sequence-to-sequence architecture with self-attention for translation. We will train the model using a sample dataset and then use this model for English to Spanish translation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives for this Notebook    \n",
    "* How to use the Keras library to build transformers model\n",
    "* Train the transformer model using a given dataset\n",
    "* Use the trained transformer model to translate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 4>\n",
    "1. <a href=\"#Import-Keras-and-Packages\">Import Keras and Packages</a><br>\n",
    "2. <a href=\"#Step-1:-Data-Preparation\">Step 1: Data Preparation</a><br>\n",
    "3. <a href=\"#Step-2:-Self-Attention-Layer\">Step 2: Self-Attention Layer</a><br>\n",
    "4. <a href=\"#Step-3:-Model-Architecture\">Step 3: Model Architecture</a><br>\n",
    "5. <a href=\"#Step-4:-Training-the-Model\">Step 4: Training the Model</a><br>\n",
    "6. <a href=\"#Step-5:-Plotting-the-training-loss\">Step 5: Plotting the training loss</a><br>\n",
    "\n",
    "</font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Keras and Packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing the keras libraries and the packages that we would need to build a neural network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following required libraries are __not__ pre-installed in the Skills Network Labs environment. __You will need to run the following cell__ to install them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.17.1\n",
      "  Downloading tensorflow-2.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow==2.17.1)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow==2.17.1)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow==2.17.1)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow==2.17.1)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow==2.17.1)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow==2.17.1)\n",
      "  Downloading h5py-3.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow==2.17.1)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow==2.17.1)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow==2.17.1)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.17.1)\n",
      "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==2.17.1)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow==2.17.1)\n",
      "  Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.17.1)\n",
      "  Downloading grpcio-1.74.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow==2.17.1)\n",
      "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.2.0 (from tensorflow==2.17.1)\n",
      "  Downloading keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting numpy<2.0.0,>=1.26.0 (from tensorflow==2.17.1)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow==2.17.1) (0.45.1)\n",
      "Collecting rich (from keras>=3.2.0->tensorflow==2.17.1)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.2.0->tensorflow==2.17.1)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.2.0->tensorflow==2.17.1)\n",
      "  Downloading optree-0.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.1) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.1) (2024.12.14)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.18,>=2.17->tensorflow==2.17.1)\n",
      "  Downloading markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow==2.17.1)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.18,>=2.17->tensorflow==2.17.1)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow==2.17.1) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.2.0->tensorflow==2.17.1)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow==2.17.1) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow==2.17.1)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.4/601.4 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.74.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.11.3-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m291.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n",
      "Downloading markdown-3.9-py3-none-any.whl (107 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (408 kB)\n",
      "Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, markdown, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, ml-dtypes, markdown-it-py, h5py, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.74.0 h5py-3.14.0 keras-3.11.3 libclang-18.1.1 markdown-3.9 markdown-it-py-4.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.1.0 numpy-1.26.4 opt-einsum-3.4.0 optree-0.17.0 protobuf-4.25.8 rich-14.1.0 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.1 termcolor-3.1.0 werkzeug-3.1.3 wrapt-1.17.3\n",
      "Collecting matplotlib==3.9.2\n",
      "  Downloading matplotlib-3.9.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib==3.9.2)\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib==3.9.2)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib==3.9.2)\n",
      "  Downloading fonttools-4.59.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (109 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib==3.9.2)\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.2) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib==3.9.2)\n",
      "  Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib==3.9.2)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.2) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib==3.9.2) (1.17.0)\n",
      "Downloading matplotlib-3.9.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m132.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m143.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.59.2 kiwisolver-1.4.9 matplotlib-3.9.2 pillow-11.3.0 pyparsing-3.2.3\n",
      "==== All required libraries are installed =====\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.17.1\n",
    "!pip install matplotlib==3.9.2\n",
    "\n",
    "print(\"==== All required libraries are installed =====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppress the tensorflow warning messages\n",
    "We use the following code to  suppress the warning messages due to use of CPU architechture for tensoflow.\n",
    "\n",
    "You may want to **comment out** these lines if you are using the GPU architechture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To use Keras, you will also need to install a backend framework – such as TensorFlow.\n",
    "\n",
    "If you install TensorFlow 2.16 or above, it will install Keras by default.\n",
    "\n",
    "We are using the CPU version of tensorflow since we are dealing with smaller datasets. \n",
    "You may install the GPU version of tensorflow on your machine to accelarate the processing of larger datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 23:06:55.672197: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-11 23:06:55.692455: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-11 23:06:55.698118: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.layers import Layer\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data Preparation\n",
    "We start by define the sentences and text for translation training\n",
    "Sentence Pairs: Defines a small dataset of English-Spanish sentence pairs.\n",
    "Target Sequences:\n",
    "Prepends \"startseq\" and appends \"endseq\" to each target sentence for the decoder to learn when to start and stop translating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample parallel sentences (English -> Spanish)\n",
    "input_texts = [\n",
    "    \"Hello.\", \"How are you?\", \"I am learning machine translation.\", \"What is your name?\", \"I love programming.\"\n",
    "]\n",
    "target_texts = [\n",
    "    \"Hola.\", \"¿Cómo estás?\", \"Estoy aprendiendo traducción automática.\", \"¿Cuál es tu nombre?\", \"Me encanta programar.\"\n",
    "]\n",
    "\n",
    "target_texts = [\"startseq \" + x + \" endseq\" for x in target_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, we convert the text from the sentences to tokens and create a vocabulary\n",
    "Tokenization: Uses Tokenizer to convert words into numerical sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "input_tokenizer = Tokenizer()\n",
    "input_tokenizer.fit_on_texts(input_texts)\n",
    "input_sequences = input_tokenizer.texts_to_sequences(input_texts)\n",
    "\n",
    "output_tokenizer = Tokenizer()\n",
    "output_tokenizer.fit_on_texts(target_texts)\n",
    "output_sequences = output_tokenizer.texts_to_sequences(target_texts)\n",
    "\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "output_vocab_size = len(output_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now pad the corresponding sentences\n",
    "Padding: Ensures all sequences have the same length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "max_input_length = max([len(seq) for seq in input_sequences])\n",
    "max_output_length = max([len(seq) for seq in output_sequences])\n",
    "\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_input_length, padding='post')\n",
    "output_sequences = pad_sequences(output_sequences, maxlen=max_output_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the target data for training\n",
    "decoder_input_data = output_sequences[:, :-1]\n",
    "decoder_output_data = output_sequences[:, 1:]\n",
    "\n",
    "# Convert to one-hot\n",
    "decoder_output_data = np.array([np.eye(output_vocab_size)[seq] for seq in decoder_output_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Self-Attention Layer\n",
    "Self-attention is a mechanism that allows a model to **focus on relevant parts of the input sequence** while processing each word. This is particularly useful in:\n",
    "1) Machine Translation (e.g., aligning words correctly)\n",
    "2) Text Summarization\n",
    "3) Speech Recognition\n",
    "4) Image Processing (Vision Transformers)\n",
    "In this implementation, self-attention is used for text based sequence-to-sequence modeling.\n",
    "\n",
    "\n",
    "Self-Attention works for a given an input sequence by computing a weighted representation of all words for each position. It does so using three key components:\n",
    "\n",
    "1. Query **(Q)**, Key **(K)**, and Value **(V)** Matrices\n",
    "For each word (token) in a sequence:\n",
    "\n",
    "Query (Q): What this word is looking for.\n",
    "Key (K): What this word represents.\n",
    "Value (V): The actual information in the word.\n",
    "\n",
    "2. Compute **Attention Scores**\n",
    "Next, we **calculate the similarity between each query and key** using dot-product attention:\n",
    "Each word in a sequence attends to every other word based on these scores.\n",
    "\n",
    "3. Apply **Scaling & Softmax**\n",
    "Since dot-product values can be large, we scale them. \n",
    "Next, Applying softmax converts scores into attention weights:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Attention class\n",
    "In this implementation of self-attention layer:\n",
    "1. We first initialize the weights in the **build** method, where:\n",
    "    1. **self.Wq**, **self.Wk**, **self.Wv** are the trainable weight matrices.\n",
    "    2. Their **shape is (feature_dim, feature_dim)**, meaning they transform input features into Q, K, and V representations.\n",
    "2. Applying Attention using **call** method. The **call()** method:\n",
    "   1. Computes **Q, K, V** by multiplying inputs (encoder/decoder output) with their respective weight matrices.\n",
    "   2. Computes **dot-product attention scores** using K.batch_dot(q, k, axes=[2, 2]), resulting in a (batch_size, seq_len, seq_len) matrix.\n",
    "   3. **Scales** the scores to avoid large values.\n",
    "   4. Applies **softmax** to normalize the attention scores.\n",
    "   5. **Multiplies attention weights with V** to get the final output.\n",
    "3. The **compute_output_shape** method defines the shape of the output tensor after the layer processes an input.\n",
    "    1. The output shape of the Self-Attention layer **remains the same** as the input shape.\n",
    "    2. The attention mechanism **transforms** the input but does not change its dimensions.4\n",
    "    3. If the attention layer changed the shape, you would modify compute_output_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Self-Attention Layer\n",
    "class SelfAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        feature_dim = input_shape[-1]\n",
    "        # Weight matrices for Q, K, V\n",
    "        self.Wq = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='glorot_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wq')\n",
    "        self.Wk = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='glorot_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wk')\n",
    "        self.Wv = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='glorot_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wv')\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Linear projections\n",
    "        q = K.dot(inputs, self.Wq)  # Query\n",
    "        k = K.dot(inputs, self.Wk)  # Key\n",
    "        v = K.dot(inputs, self.Wv)  # Value\n",
    "\n",
    "        # Scaled Dot-Product Attention\n",
    "        scores = K.batch_dot(q, k, axes=[2, 2])  # (batch, seq_len, seq_len)\n",
    "        scores = scores / K.sqrt(K.cast(K.shape(k)[-1], dtype=K.floatx()))  # Scale\n",
    "        attention_weights = K.softmax(scores, axis=-1)  # Normalize\n",
    "\n",
    "        # Weighted sum of values\n",
    "        output = K.batch_dot(attention_weights, v)  # (batch, seq_len, feature_dim)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Model Architecture\n",
    "The model follows an Encoder-Decoder structure:\n",
    "\n",
    "### Encoder:\n",
    "1) Takes input sentences (padded and tokenized).\n",
    "2) Uses an Embedding layer (word representations) + LSTM (to process sequences).\n",
    "    1. The LSTMs are used as the **help process variable-length input sentences** and generate meaningful translations.\n",
    "4) Outputs context vectors (hidden & cell states).\n",
    "\n",
    "### Attention Layer\n",
    "1) Applied to both the encoder and decoder outputs.\n",
    "2) Helps the decoder focus on relevant words during translation.\n",
    "\n",
    "### Decoder\n",
    "1) Receives target sequences (shifted one step ahead).\n",
    "2) Uses an LSTM with encoder states as initial states.\n",
    "3) Applies self-attention for better learning.\n",
    "4) Uses a Dense layer (Softmax) to predict the next word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],       │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ additive_attention  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>) │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ additive_attenti… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,721</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,096\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,352\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],       │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ additive_attention  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mAdditiveAttention\u001b[0m) │                   │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ additive_attenti… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m17\u001b[0m)     │      \u001b[38;5;34m8,721\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,068,049</span> (4.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,068,049\u001b[0m (4.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,068,049</span> (4.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,068,049\u001b[0m (4.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import AdditiveAttention, Concatenate, Dense, Embedding, Input, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    " \n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_input_length,))\n",
    "encoder_embedding = Embedding(input_vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    " \n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_output_length - 1,))\n",
    "decoder_embedding = Embedding(output_vocab_size, 256)(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    " \n",
    "# Attention: decoder attends to encoder outputs\n",
    "attention = AdditiveAttention()\n",
    "attention_output = attention([decoder_outputs, encoder_outputs])\n",
    " \n",
    "# Combine decoder outputs with attention context\n",
    "decoder_concat = Concatenate(axis=-1)([decoder_outputs, attention_output])\n",
    " \n",
    "# Final Dense layer\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_concat)\n",
    " \n",
    "# Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    " \n",
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Training the Model\n",
    "Uses categorical_crossentropy as the loss function since output words are one-hot encoded.\n",
    "Trains using Adam optimizer for 100 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.0800 - loss: 2.8320\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.3600 - loss: 2.7992\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.3200 - loss: 2.7645\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.3200 - loss: 2.7244\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.3200 - loss: 2.6749\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.3200 - loss: 2.6110\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.2800 - loss: 2.5267\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 0.2800 - loss: 2.4155\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.2800 - loss: 2.2775\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.2400 - loss: 2.1383\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.2400 - loss: 2.0628\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.2400 - loss: 2.0669\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.2800 - loss: 2.0487\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.2800 - loss: 1.9895\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.3600 - loss: 1.9258\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.4400 - loss: 1.8666\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.4400 - loss: 1.8072\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.4800 - loss: 1.7497\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.5200 - loss: 1.6960\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.5200 - loss: 1.6444\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.6000 - loss: 1.5922\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.4800 - loss: 1.5376\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.4800 - loss: 1.4800\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.4800 - loss: 1.4194\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.4800 - loss: 1.3549\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.4800 - loss: 1.2852\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.5600 - loss: 1.2096\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.6000 - loss: 1.1313\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.6400 - loss: 1.0573\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.7200 - loss: 0.9928\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.7600 - loss: 0.9354\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.7600 - loss: 0.8780\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.7200 - loss: 0.8202\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.8400 - loss: 0.7648\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8800 - loss: 0.7105\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.9200 - loss: 0.6583\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.9600 - loss: 0.6114\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 1.0000 - loss: 0.5665\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.5219\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.4802\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.4399\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.4024\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.3697\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 1.0000 - loss: 0.3381\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 1.0000 - loss: 0.3076\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 1.0000 - loss: 0.2819\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.2594\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.2386\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.2192\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.2005\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.1833\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.1669\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.1527\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.1405\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.1284\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 1.0000 - loss: 0.1176\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.1079\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.0987\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0904\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0827\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 1.0000 - loss: 0.0762\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0701\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 0.0646\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 0.0597\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.0552\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.0509\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.0472\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0438\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.0408\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 1.0000 - loss: 0.0380\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 0.0354\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.0330\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0309\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.0290\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.0273\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 1.0000 - loss: 0.0257\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0242\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0229\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 1.0000 - loss: 0.0216\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0205\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0194\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 1.0000 - loss: 0.0185\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.0176\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.0168\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.0160\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 1.0000 - loss: 0.0153\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0146\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0140\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.0134\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0129\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 1.0000 - loss: 0.0124\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.0119\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 1.0000 - loss: 0.0115\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.0111\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.0107\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.0103\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.0100\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.0097\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.0094\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0091\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Train the Model\n",
    "history_glorot_adam = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Plotting the training loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting training loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Awesome, now you have succesfully trained a transformers model.\n",
    "### Now let's try some practice excercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice excercise 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practice exercise, let's train the model using \"he_uniform\" initializer instead of \"glorot_uniform\". Then, compare the training loss between model using \"glorot_uniform\" vs \"he_uniform\" initializers by plotting them using matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.0800 - loss: 2.8315\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.3200 - loss: 2.8008\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.3200 - loss: 2.7677\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.3200 - loss: 2.7292\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.3200 - loss: 2.6818\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.3200 - loss: 2.6207\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.3200 - loss: 2.5397\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.3200 - loss: 2.4317\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.2800 - loss: 2.2938\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.2800 - loss: 2.1435\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.2800 - loss: 2.0357\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.2800 - loss: 2.0120\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.2800 - loss: 1.9996\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.3200 - loss: 1.9489\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.4000 - loss: 1.8898\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.5200 - loss: 1.8370\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.5200 - loss: 1.7732\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.5200 - loss: 1.7040\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.5600 - loss: 1.6415\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.5600 - loss: 1.5888\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.4800 - loss: 1.5422\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.4800 - loss: 1.4962\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.4400 - loss: 1.4471\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.4400 - loss: 1.3926\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.4400 - loss: 1.3314\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.4400 - loss: 1.2631\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.5200 - loss: 1.1903\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.6000 - loss: 1.1177\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.6400 - loss: 1.0477\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.6800 - loss: 0.9800\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.7200 - loss: 0.9156\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7600 - loss: 0.8534\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.8000 - loss: 0.7900\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.8400 - loss: 0.7269\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.8800 - loss: 0.6685\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.9200 - loss: 0.6159\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.9600 - loss: 0.5701\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 1.0000 - loss: 0.5303\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.4904\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.4503\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.4143\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.3829\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.3554\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.3275\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 0.3016\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 1.0000 - loss: 0.2771\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.2536\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.2321\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.2148\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.1986\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.1826\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.1667\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.1530\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.1403\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.1293\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.1195\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.1101\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.1005\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0921\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 0.0850\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.0788\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.0727\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0671\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 1.0000 - loss: 0.0619\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 1.0000 - loss: 0.0572\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.0530\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0494\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 1.0000 - loss: 0.0462\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.0430\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.0400\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0374\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 0.0351\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0330\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0310\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.0292\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 0.0275\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 1.0000 - loss: 0.0259\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.0245\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0232\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.0220\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0209\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0199\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0189\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0180\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0172\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0164\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0157\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0151\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0145\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.0139\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.0134\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.0129\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0124\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0120\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0116\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.0112\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0108\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0105\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.0101\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0098\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABbMUlEQVR4nO3deZxO5f/H8dc9+2I228zIWEL2LeuQkClpIypJWSq+tiJaSAg/oSiVok2UXVlKiGxFZFfWyM6MJWY1+31+f5zcmawzZubM3PN+Ph7nMee+zjn3/blPMm/nXNe5bIZhGIiIiIg4CRerCxARERHJTgo3IiIi4lQUbkRERMSpKNyIiIiIU1G4EREREaeicCMiIiJOReFGREREnIrCjYiIiDgVhRsRERFxKgo3IpLjunTpQpkyZbJ07JtvvonNZsvegkTEqSnciBRgNpvtppY1a9ZYXaolunTpQqFChawuQ0Qyyaa5pUQKrunTp2d4/dVXX7FixQq+/vrrDO333nsvwcHBWf6c1NRU7HY7np6emT42LS2NtLQ0vLy8svz5WdWlSxe++eYb4uPjc/2zRSTr3KwuQESs8/TTT2d4vXHjRlasWHFF+39dvHgRHx+fm/4cd3f3LNUH4Obmhpub/qoSkZun21Iicl3NmjWjWrVqbN26lbvvvhsfHx9ef/11ABYtWsSDDz5IiRIl8PT0pFy5cowcOZL09PQM7/HfPjdHjhzBZrMxbtw4Pv30U8qVK4enpyf16tVj8+bNGY69Wp8bm81Gnz59WLhwIdWqVcPT05OqVauybNmyK+pfs2YNdevWxcvLi3LlyvHJJ59kez+eefPmUadOHby9vSlatChPP/00J0+ezLBPVFQUXbt2pWTJknh6ehIaGkrr1q05cuSIY58tW7bQsmVLihYtire3N2XLluXZZ5/NtjpFCgr9c0hEbujvv/+mVatWPPnkkzz99NOOW1RTp06lUKFC9O/fn0KFCrFq1SqGDh1KbGws77zzzg3fd+bMmcTFxfG///0Pm83G22+/Tdu2bTl06NANr/asW7eO+fPn06tXL/z8/Pjggw9o164dx44do0iRIgBs376d+++/n9DQUIYPH056ejojRoygWLFit35S/jF16lS6du1KvXr1GD16NKdPn+b9999n/fr1bN++ncDAQADatWvH7t27eeGFFyhTpgxnzpxhxYoVHDt2zPH6vvvuo1ixYgwcOJDAwECOHDnC/Pnzs61WkQLDEBH5R+/evY3//rXQtGlTAzAmT558xf4XL168ou1///uf4ePjYyQlJTnaOnfubJQuXdrx+vDhwwZgFClSxDh//ryjfdGiRQZgfP/99462YcOGXVETYHh4eBgHDx50tO3cudMAjA8//NDR9vDDDxs+Pj7GyZMnHW0HDhww3NzcrnjPq+ncubPh6+t7ze0pKSlG8eLFjWrVqhmJiYmO9sWLFxuAMXToUMMwDOPChQsGYLzzzjvXfK8FCxYYgLF58+Yb1iUi16fbUiJyQ56ennTt2vWKdm9vb8d6XFwc586do0mTJly8eJF9+/bd8H3bt29PUFCQ43WTJk0AOHTo0A2PjYiIoFy5co7XNWrUwN/f33Fseno6P/30E23atKFEiRKO/cqXL0+rVq1u+P43Y8uWLZw5c4ZevXpl6PD84IMPUqlSJX744QfAPE8eHh6sWbOGCxcuXPW9Ll3hWbx4MampqdlSn0hBpXAjIjd022234eHhcUX77t27efTRRwkICMDf359ixYo5OiPHxMTc8H1LlSqV4fWloHOtAHC9Yy8df+nYM2fOkJiYSPny5a/Y72ptWXH06FEAKlaseMW2SpUqObZ7enoyduxYli5dSnBwMHfffTdvv/02UVFRjv2bNm1Ku3btGD58OEWLFqV169Z8+eWXJCcnZ0utIgWJwo2I3NDlV2guiY6OpmnTpuzcuZMRI0bw/fffs2LFCsaOHQuA3W6/4fu6urpetd24iSdU3MqxVujXrx9//vkno0ePxsvLiyFDhlC5cmW2b98OmJ2kv/nmGzZs2ECfPn04efIkzz77LHXq1NFQdJFMUrgRkSxZs2YNf//9N1OnTqVv37489NBDREREZLjNZKXixYvj5eXFwYMHr9h2tbasKF26NAD79++/Ytv+/fsd2y8pV64cAwYMYPny5ezatYuUlBTGjx+fYZ+GDRsyatQotmzZwowZM9i9ezezZ8/OlnpFCgqFGxHJkktXTi6/UpKSksLHH39sVUkZuLq6EhERwcKFCzl16pSj/eDBgyxdujRbPqNu3boUL16cyZMnZ7h9tHTpUvbu3cuDDz4ImM8FSkpKynBsuXLl8PPzcxx34cKFK6461apVC0C3pkQySUPBRSRLGjVqRFBQEJ07d+bFF1/EZrPx9ddf56nbQm+++SbLly+ncePG9OzZk/T0dCZOnEi1atXYsWPHTb1Hamoq//d//3dFe+HChenVqxdjx46la9euNG3alA4dOjiGgpcpU4aXXnoJgD///JMWLVrwxBNPUKVKFdzc3FiwYAGnT5/mySefBGDatGl8/PHHPProo5QrV464uDg+++wz/P39eeCBB7LtnIgUBAo3IpIlRYoUYfHixQwYMIA33niDoKAgnn76aVq0aEHLli2tLg+AOnXqsHTpUl5++WWGDBlCWFgYI0aMYO/evTc1mgvMq1FDhgy5or1cuXL06tWLLl264OPjw5gxY3jttdfw9fXl0UcfZezYsY4RUGFhYXTo0IGVK1fy9ddf4+bmRqVKlZg7dy7t2rUDzA7FmzZtYvbs2Zw+fZqAgADq16/PjBkzKFu2bLadE5GCQHNLiUiB06ZNG3bv3s2BAwesLkVEcoD63IiIU0tMTMzw+sCBAyxZsoRmzZpZU5CI5DhduRERpxYaGkqXLl24/fbbOXr0KJMmTSI5OZnt27dToUIFq8sTkRygPjci4tTuv/9+Zs2aRVRUFJ6enoSHh/PWW28p2Ig4MV25EREREaeiPjciIiLiVBRuRERExKkUuD43drudU6dO4efnh81ms7ocERERuQmGYRAXF0eJEiVwcbn+tZkCF25OnTpFWFiY1WWIiIhIFhw/fpySJUted58CF278/PwA8+T4+/tbXI2IiIjcjNjYWMLCwhy/x6+nwIWbS7ei/P39FW5ERETymZvpUqIOxSIiIuJUFG5ERETEqSjciIiIiFMpcH1uREQke9jtdlJSUqwuQ5yIh4fHDYd53wyFGxERybSUlBQOHz6M3W63uhRxIi4uLpQtWxYPD49beh+FGxERyRTDMIiMjMTV1ZWwsLBs+Ze2yKWH7EZGRlKqVKlbetCuwo2IiGRKWloaFy9epESJEvj4+FhdjjiRYsWKcerUKdLS0nB3d8/y+yhui4hIpqSnpwPc8q0Dkf+69Gfq0p+xrFK4ERGRLNH8fJLdsuvPlMKNiIiIOBWFGxERkX+UKVOGCRMmWF1GjnnzzTepVavWFW3BwcHYbDYWLlxoSV3ZTeFGREQkl10tZOSGl19+mZUrVzpe7927l+HDh/PJJ58QGRlJq1atcr2mnKBwk402fbyFpDOxVpchIiIWyesPNSxUqBBFihRxvP7rr78AaN26NSEhIXh6embpfVNTU7OlvuyicJNN/pi+k3t6V6JZmSOc3HTS6nJEROQq4uLi6NixI76+voSGhvLee+/RrFkz+vXrd9X9jx07RuvWrSlUqBD+/v488cQTnD592rH90hWYzz//nLJly+Ll5XXD46ZOncrw4cPZuXMnNpsNm83G1KlTr1v3kSNHsNls7Nixw9EWHR2NzWZjzZo1AKxZswabzcbKlSupW7cuPj4+NGrUiP37919R76X1hx9+GDAfnnepM6/dbmfEiBGULFkST09PatWqxbJly66oZc6cOTRt2hQvLy9mzJhBly5daNOmDW+99RbBwcEEBgYyYsQI0tLSeOWVVyhcuDAlS5bkyy+/vOF/p1ulcJNN/k7wwsOWym+JNagb7sb6L/ZZXZKISO4wDEhIsGYxjEyV2r9/f9avX893333HihUr+OWXX9i2bdtV97Xb7bRu3Zrz58+zdu1aVqxYwaFDh2jfvn2G/Q4ePMi3337L/Pnz2bFjxw2Pa9++PQMGDKBq1apERkYSGRl5xXveisGDBzN+/Hi2bNmCm5sbzz777FX3e/nllx1B41IdAO+//z7jx49n3Lhx/P7777Rs2ZJHHnmEAwcOZDh+4MCB9O3bl71799KyZUsAVq1axalTp/j555959913GTZsGA899BBBQUH89ttv9OjRg//973+cOHEi277vVRkFTExMjAEYMTEx2f7eB38+aVT33G+AYbiTbEzuuT3bP0NExGqJiYnGnj17jMTERLMhPt4wzJiR+0t8/E3XHRsba7i7uxvz5s1ztEVHRxs+Pj5G3759DcMwjNKlSxvvvfeeYRiGsXz5csPV1dU4duyYY//du3cbgLFp0ybDMAxj2LBhhru7u3HmzBnHPjd7XM2aNW+69sOHDxuAsX37dkfbhQsXDMBYvXq1YRiGsXr1agMwfvrpJ8c+P/zwgwE4/lv993MXLFhg/DcKlChRwhg1alSGtnr16hm9evXKUMuECRMy7NO5c2ejdOnSRnp6uqOtYsWKRpMmTRyv09LSDF9fX2PWrFlX/Z5X/Nm6TGZ+f+vKTTYq16QEvx4K4bHgX0jFgx6TavG/8N9JSc7cvyxERCT7HTp0iNTUVOrXr+9oCwgIoGLFilfdf+/evYSFhREWFuZoq1KlCoGBgezdu9fRVrp0aYoVK5bp43JKjRo1HOuhoaEAnDlz5qaOjY2N5dSpUzRu3DhDe+PGja+ovW7dulccX7Vq1QzTcQQHB1O9enXHa1dXV4oUKXLT9WSVpl/IZoVK+DP3eDhjmyzg9d9a8+nGGhwo/yff7ihPUBFlSRFxQj4+EB9v3WdbzNfXN8c/41JgMC67DXetTryXT1tweT+a7Ha17/3fKRNsNttV23J6wlX9ts0BNnc3Bm5ow+LnFuJHLKtP3EGj2yM5vD9v96IXEckSmw18fa1ZMvFE29tvvx13d3c2b97saIuJieHPP/+86v6VK1fm+PHjHD9+3NG2Z88eoqOjqVKlyjU/52aO8/DwyNQUA5euDF3qFwNk6FycXfz9/SlRogTr16/P0L5+/frrfue8RlducorNxgOft2Vd+SU8OKg6+2LDaFjjAt8tTaXBPTmf8kVEJCM/Pz86d+7sGLlTvHhxhg0blmGk0OUiIiKoXr06HTt2ZMKECaSlpdGrVy+aNm161VsymTmuTJkyHD58mB07dlCyZEn8/PyuOwzb29ubhg0bMmbMGMqWLcuZM2d44403bv2kXMUrr7zCsGHDKFeuHLVq1eLLL79kx44dzJgxI0c+Lyfoyk0OqzHwATbOOEQtl52cSQmiWYQrC6ZGW12WiEiB9O677xIeHs5DDz1EREQEjRs3pnLlyo4h3Jez2WwsWrSIoKAg7r77biIiIrj99tuZM2fOdT/jZo5r164d999/P82bN6dYsWLMmjXrhrVPmTKFtLQ06tSpQ79+/fi///u/zJ+Am/Diiy/Sv39/BgwYQPXq1Vm2bBnfffcdFSpUyJHPywk24/IbeAVAbGwsAQEBxMTE4O/vn2ufG7dmK0/ed54lqffiQjozJ8fR/n+Bufb5IiLZJSkpicOHD2d4rkt+lZCQwG233cb48eN57rnnrC6nwLven63M/P7WlZtc4tesDot2lKaL71zsuNKxRyHmfhFndVkiIgXK9u3bmTVrFn/99Rfbtm2jY8eOgPmEXnEeCje5yK3KHXyx7U66eM8hHTeeet6bedMuWl2WiEiBMm7cOGrWrElERAQJCQn88ssvFC1a1NKaZsyYQaFCha66VK1a1dLa8iN1KM5lLneU5/PfUjDqzWJacgc6dAGbaxKPPZ2/L+2KiOQHtWvXZuvWrVaXcYVHHnmEBg0aXHXbf4dSy40p3FjAtXoVvvglCaPxLL5K7cCTnWws9EnhobYeVpcmIiIW8PPzw8/Pz+oynIZuS1nEtd6dTFlZmqddZ5FuuPLUk+ns3VOg+naLiIjkCIUbC7k2acSU74vRlDXEpXrTunkM0dFWVyUiIpK/KdxYzL1VBPPe+J1SHOXAmUCeejCGTDy0UkRERP5D4SYPKDbiBRY0fR9vLrL01wCGvJxodUkiIiL5lsJNXmCzcefCoXxefDAAoyd4M3d2zk4qJiIi4qwUbvKKwECeWt6Fl13fA6BrpzQOH7a4JhERJ9KsWTP69etndRnXZbPZWLhwoeP1vn37aNiwIV5eXtSqVcuyuvIbhZu8pGZNxnxWhLtZy8VUD3o/E0PBmhxDRKRgi4yMpFWrVo7Xw4YNw9fXl/3797Ny5UoLK8tfFG7yGNeunfik1SI8SGbp+gDmzdHtKRGRgiIkJCTD7OB//fUXd911F6VLl6ZIkSJZes+UlJTsKi/fULjJgyp9NoBB7uMB6NsjScPDRUSyid1u59VXX6Vw4cKEhITw5ptvOrZFR0fz/PPPU6xYMfz9/bnnnnvYuXPnTb1vly5daNOmTYa2fv360axZM8frZs2a8eKLL17z8yHjbSmbzcbWrVsZMWIENpvNse8ff/zBPffcg7e3N0WKFKF79+7Ex8dfUcuoUaMoUaIEFStW5MiRI9hsNubOnUuTJk3w9vamXr16/Pnnn2zevJm6detSqFAhWrVqxdmzZ2/2dOZZCjd50W23MXC4N3ewn6gYH14fkGR1RSIi12QYkJBgzZLZW/fTpk3D19eX3377jbfffpsRI0awYsUKAB5//HHOnDnD0qVL2bp1K3feeSctWrTg/Pnz2Xaurvf5/xUZGUnVqlUZMGAAkZGRvPzyyyQkJNCyZUuCgoLYvHkz8+bN46effqJPnz4Zjl25ciX79+9nxYoVLF682NE+bNgw3njjDbZt24abmxtPPfUUr776Ku+//z6//PILBw8eZOjQodn2fS1jFDAxMTEGYMTExFhdyvWlpBirSnU2wDBspBu//mp1QSIipsTERGPPnj1GYmKiYRiGER9vGGbMyP0lPv7m627atKlx1113ZWirV6+e8dprrxm//PKL4e/vbyQlJWXYXq5cOeOTTz654Xt37tzZaN26dYa2vn37Gk2bNr2pz78EMBYsWOB4XbNmTWPYsGGO159++qkRFBRkxF/2xX/44QfDxcXFiIqKctQSHBxsJCcnO/Y5fPiwARiff/65o23WrFkGYKxcudLRNnr0aKNixYo3/L455b9/ti6Xmd/funKTV7m70/zLTnRmKgYudO+USGqq1UWJiORvNWrUyPA6NDSUM2fOsHPnTuLj4ylSpEiGGbkPHz7MX3/9leOff7P27t1LzZo18fX1dbQ1btwYu93O/v37HW3Vq1fHw+PK+Qov//zg4GDHvpe3ZaaevEoTZ+Zl99zDuDbdWLzwIXYdLMr7E+y8/IryqIjkLT4+cFmXj1z/7Mz47wzbNpsNu91OfHw8oaGhrFmz5opjAgMDb/i+Li4uGP+5R5Z6lX+RXuvzs9vl4edan2+z2a7alhP15DaFmzyu6IfDGLtkKM+nfMzbI5Pp1ds70/8zi4jkJJsNrvG7NN+48847iYqKws3NjTJlymT6+GLFirFr164MbTt27LgizNyqypUrM3XqVBISEhwBZv369bi4uFCxYsVs/az8TJcB8rqSJek8rAxlOMzZOG+mfJ7/E7WISF4TERFBeHg4bdq0Yfny5Rw5coRff/2VwYMHs2XLlhsef88997Blyxa++uorDhw4wLBhw64IO9mhY8eOeHl50blzZ3bt2sXq1at54YUXeOaZZxy3mUThJl9we7EXr3h/BMA7I5PU90ZEJJvZbDaWLFnC3XffTdeuXbnjjjt48sknOXr06E2FhpYtWzJkyBBeffVV6tWrR1xcHJ06dcr2On18fPjxxx85f/489erV47HHHqNFixZMnDgx2z8rP7MZ/71J6ORiY2MJCAggJiYGf39/q8u5aYmvDqPMO704QzDTpkEO/D8jInJTkpKSOHz4MGXLlsXLy8vqcsSJXO/PVmZ+f+vKTT7h/VIP+rl+CMCYYRdxgv5eIiIiOULhJr8IDaXXUzH4E8PeIz58953VBYmIFBxVq1bNMET88mXGjBlWlyf/odFS+UjAwJ70+vpjxjCI0cOSaN3ai39G8omISA5asmTJVYd2A+rImwcp3OQnVarQL+ItJvyUyKbfvVmzBpo3t7ooERHnV7p0aatLkEzQbal8Jnjw8zzLFABGDy94M72KiIjciMJNftO0Ka9UW4YraaxY68Eff1hdkIgUVAVssK3kguz6M2XpbanRo0czf/589u3bh7e3N40aNWLs2LHXfcri1KlT6dq1a4Y2T09PkpIKyMzZNhtl3niaR578jgW0Zca0VMaMy94nYIqIXI+7uzs2m42zZ89SrFgxx2P8RW6FYRicPXsWm812y092tjTcrF27lt69e1OvXj3S0tJ4/fXXue+++9izZ88158UA8Pf3zzBBWIH7H6tdOzoW7cOCc22ZOTWVt952x0XX4EQkl7i6ulKyZElOnDjBkSNHrC5HnIjNZqNkyZK4urre0vtYGm6WLVuW4fXUqVMpXrw4W7du5e67777mcTabjZCQkJwuL+9yc+PBLsXwHxfD8b8DWLcOrnO6RESyXaFChahQocI1RxCJZIW7u/stBxvIY6OlYmJiAChcuPB194uPj6d06dLY7XbuvPNO3nrrLapWrXrVfZOTk0lOTna8jo2Nzb6CLeT19GO0G/ctX/IsM75M4e67r5zaXkQkJ7m6umbLLyKR7JZnbmbY7Xb69etH48aNqVat2jX3q1ixIlOmTGHRokVMnz4du91Oo0aNOHHixFX3Hz16NAEBAY4lLCwsp75C7qpRg45hvwAwb55BigZOiYiIAHlobqmePXuydOlS1q1bR8mSJW/6uNTUVCpXrkyHDh0YOXLkFduvduUmLCws380tdTXpw0YQNuJ5IinBokXwyCNWVyQiIpIz8t3cUn369GHx4sWsXr06U8EGzPtztWvX5uDBg1fd7unpib+/f4bFWbg+1Z4nmQ3AjCnJN9hbRESkYLA03BiGQZ8+fViwYAGrVq2ibNmymX6P9PR0/vjjD0JDQ3OgwjyuYkU6VtwKwHdLXImLs7geERGRPMDScNO7d2+mT5/OzJkz8fPzIyoqiqioKBITEx37dOrUiUGDBjlejxgxguXLl3Po0CG2bdvG008/zdGjR3n++eet+AqWu7NrTSqyj6RUNxYssLoaERER61kabiZNmkRMTAzNmjUjNDTUscyZM8exz7Fjx4iMjHS8vnDhAt26daNy5co88MADxMbG8uuvv1KlShUrvoLlbO2foCPmjLS6NSUiIpKHOhTnlsx0SMovDtZ+nAo75uFis3PylAsF+RFAIiLinPJdh2K5NeW7NqEBG7EbLsyda3U1IiIi1lK4cQaPP05HZgIw9+sCMseWiIjINSjcOIPQUB4JPwvAxm0eREdbW46IiIiVFG6cROkuzanIPtLtLqxcaXU1IiIi1lG4cRYPPkhLfgTgx0W6NSUiIgWXwo2zuO02WpbeD8CPS9MpWGPgRERE/qVw40Satg7Eg2SOnfNl/36rqxEREbGGwo0T8X2oOU0wZwr/cZku3YiISMGkcONMmjThfjezN/GP38ZbXIyIiIg1FG6ciZcXLRtEA7DmNy+S1K9YREQKIIUbJ1OtXUVKcJLEVHfWrbO6GhERkdyncONkbPe35D6WA/Dj4lSLqxEREcl9CjfOplIlWhbZAuh5NyIiUjAp3Dgbm417W7ljw84fR/w4dcrqgkRERHKXwo0TKtL6LupiXr1ZvtziYkRERHKZwo0zatGClpf63SxIsLgYERGR3KVw44yCgmhZ9QQAK1a6kp5ucT0iIiK5SOHGSTVoexv+xPB3ghfbtlldjYiISO5RuHFS7g/cyz2sAmDVT7p0IyIiBYfCjbOqV4/m3r8BsGphrMXFiIiI5B6FG2fl6krzJuZD/NZt9yUlxeJ6REREconCjROr+lgVinKWi6kebN5sdTUiIiK5Q+HGibm0vJdmrAFg9ZJEa4sRERHJJQo3zqxUKZoH7wVg9XdxFhcjIiKSOxRunFzz+9wB+HVvIEmaakpERAoAhRsnV6l9TUKIJCndg40bDKvLERERyXEKN07O1qwpzV3WArD62/PWFiMiIpILFG6cna8vzSucBGD1Mt2XEhER56dwUwA0f7gQABsPFefiRYuLERERyWEKNwVAuQ71KclxUg13fl2banU5IiIiOUrhpgCw1apJc88NAKyaEWlxNSIiIjlL4aYgcHHhntoXAFi92uJaREREcpjCTQHR/PGiAGw+VYI4Pc9PREScmMJNAVG6QyPKcoh03Fj3Q4zV5YiIiOQYhZuCIjSU5kE7AVg945TFxYiIiOQchZsCpHm4+Zybn371sbgSERGRnKNwU4Dc16UErqSx/XxpDmxTxxsREXFOCjcFSPG2d3GvrzkkfMaAbRZXIyIikjMUbgoSV1ee6mzOEj7j55IYF6KtrUdERCQHKNwUMG3eqo+3LZGD9nJsfmWu1eWIiIhkO4WbAsYvwIXWjc4BMPOrNDivmcJFRMS5KNwUQB1fvQ2A2altSXvnPYurERERyV4KNwVQy1YuFPFL5jQhrJrwO5w7Z3VJIiIi2UbhpgByd4cnOnoAMCOpLYwbl3GH9HQwDAsqExERuXUKNwVUx6dtAMynLRc/+Bxat4a6dSE01Ew/5cvDxx9DYqLFlYqIiGSOwk0B1agRlCljEI8f3ye2gO++g61bISrKvGpz6BD07g1ly8LYsRAba3XJIiIiN0XhpoCy2eCpp8yrNzMqjYRJk/4NOMePw4cfQqlScPo0DBxorq9aZXHVIiIiN2YzjILVuSI2NpaAgABiYmLw9/e3uhxL7d4N1aqBm5t5waZIkf/skJoKs2bBmDGwdy/cdpt5UECAJfWKiEjBlZnf37pyU4BVrQo1a0JaGrRoAb/99p8d3N2hUyfYssXsg3PypHkVR0REJA+zNNyMHj2aevXq4efnR/HixWnTpg379++/4XHz5s2jUqVKeHl5Ub16dZYsWZIL1Tqn996DoCDYuRPCw6FnT4iO/s9OPj7w2Wfm+uTJsHZtbpcpIiJy0ywNN2vXrqV3795s3LiRFStWkJqayn333UdCQsI1j/n111/p0KEDzz33HNu3b6dNmza0adOGXbt25WLlzqN5c9i/37xAYxhmdqlUyeyCk+HxN82aQbdu5nq3bhpFJSIieVae6nNz9uxZihcvztq1a7n77ruvuk/79u1JSEhg8eLFjraGDRtSq1YtJk+efMPPUJ+ba1u92rxyc+nimasrNG0Kjz0Gjz4KIV7RUKUKREaat6dGj7a0XhERKTjybZ+bmJgYAAoXLnzNfTZs2EBERESGtpYtW7Jhw4ar7p+cnExsbGyGRa6ueXPz9tS4cVCrlvksv1WroFcvKFkSpi4MNC/pALzzDmzfbmW5IiIiV5Vnwo3dbqdfv340btyYatWqXXO/qKgogoODM7QFBwcTFRV11f1Hjx5NQECAYwkLC8vWup2NpycMGGDmloMH4e23zWf7padDjx6wvVRrePxxs+G558zeyCIiInlIngk3vXv3ZteuXcyePTtb33fQoEHExMQ4luPHj2fr+zuzcuXglVfMUVQPPQTJyfDEExD71kSzF/L27f9eyREREckj8kS46dOnD4sXL2b16tWULFnyuvuGhIRw+vTpDG2nT58mJCTkqvt7enri7++fYZHMcXGBadPM5/gdPAjPv14cY9Rb5sY33jAf9CciIpJHWBpuDMOgT58+LFiwgFWrVlG2bNkbHhMeHs7KlSsztK1YsYLw8PCcKlOAwoVhzhzzgX/z5sFHqd2hTh1zWobXXrO6PBEREQdLw03v3r2ZPn06M2fOxM/Pj6ioKKKioki8bJhxp06dGDRokON13759WbZsGePHj2ffvn28+eabbNmyhT59+ljxFQqUhg3NfsQA/V92YUufqeaLadNg3TrL6hIREbmcpeFm0qRJxMTE0KxZM0JDQx3LnDlzHPscO3aMyMhIx+tGjRoxc+ZMPv30U2rWrMk333zDwoULr9sJWbJP377msPDUVHhiRDXiOvU2N/Turc7FIiKSJ+Sp59zkBj3n5tZFR5tDxY8ehReeT+SDb2+DCxfggw/ghResLk9ERJxQvn3OjeQPgYH/zsYw8Qtv1j83xXyhzsUiIpIHKNxIltx7L3Ttak7Z8Pzi1iTVDjc7F/fvb3VpIiJSwCncSJaNHw8hIbBvn43/q/WNOWZ85kz44QerSxMRkQJM4UayLCgIPvrIXB/7dQl2PPW2+aJnT/MqjoiIiAUUbuSWtG0L7dqZA6We29WPtLIV4PhxuGz4voiISG5SuJFbNvGf2Ri27XDlneZLzMaPP4ZffrG2MBERKZAUbuSWhYTAhAnm+tCvyrPpkf8zXzz/PCQlWVaXiIgUTAo3ki2eecacLDwtDZ76YyBxxcvBn3/CyJFWlyYiIgWMwo1kC5sNPv0USpeGvw670rvyKnPD2LGwY4eltYmISMGicCPZJjAQZswwR4R/vbYU0+tNgPR0eO45Tc0gIiK5RuFGslXjxjBsmLnec88L/OVXC7Ztg/fes7QuEREpOBRuJNsNHgx33w3xCS50KLqcVNxg6FA4eNDq0kREpABQuJFs5+oK06ebw8M3Hy7GxPLvm6Omunc352sQERHJQQo3kiPCwuDtfx5YPCyyB5FeZWH1apgyxdrCRETE6SncSI559lmoXx/iElx4pfJis3HAAIiMtLYwERFxago3kmNcXMy5p2w2mLG9Cmvv6AYxMdCrl25PiYhIjlG4kRxVty7873/meh/7+6S6esHChTBnjqV1iYiI81K4kRw3ahQUKQK7DnozMWKh2dinD5w+bWldIiLinBRuJMcVLgxjxpjrw369j8gqLeDvv3V7SkREcoTCjeQKR+fiOBuvlp0Lbm4wfz7MnWt1aSIi4mQUbiRXXOpcDDD9h8Js7TrRfNG7t25PiYhItlK4kVxTty507Giuv/xnN4waNXV7SkREsp3CjeSqUaPA0xPWrHXhh+fm/3t7auZMq0sTEREnoXAjuap0aejXz1x/ZdLtpA3+Z5bNXr3g8GHL6hIREeehcCO5btAgc2j4vn3wRfFB5lTisbHwzDOQlmZ1eSIiks8p3EiuCwiAYf9csBk63JW4yTPA3x/Wr4e33rK2OBERyfcUbsQS//sfVKgAZ87A23NKw8cfmxtGjIANG6wtTkRE8jWFG7GEh8e/D/YbPx5ONO0ITz0F6enmkKrYWGsLFBGRfEvhRizz6KNw112QmAj9+2NevSld2uxY3KeP1eWJiEg+pXAjlrHZYOJEcHWFefPgx40BMH26+cS/r7+GadOsLlFERPIhhRuxVM2a8OKL5nrv3pBU9y4YPtxs6NUL9u61rjgREcmXFG7EcsOHQ4kS8Ndf//TDGTQIWrSAixfhiSfM+1YiIiI3SeFGLOfnBxMmmOtjxsCBQ67m7anixWHXrn+f+iciInITFG4kT3jsMWjZEpKTzb7ERnAIzJhhdsz59FOYPdvqEkVEJJ9QuJE84VLnYk9PWL7c7GBMRAS8/rq5Q/fucPCgpTWKiEj+oHAjeUb58mZ3G4AXXoDTp4E334QmTSAuDp58ElJSrCxRRETyAYUbyVNeew1q1DCfXNypE9hd3MzbU4ULw9at/6YfERGRa1C4kTzFywtmzQJvb/P21LvvAmFh8OWX5g7vvgtLllhao4iI5G0KN5LnVKkC779vrg8aBJs3A4888u8DcTp3hlOnLKtPRETyNoUbyZOef94cQZWWBh06/DPV1NtvQ61acO4cPPOMOQ+ViIjIfyjcSJ50aQR4qVLmw/1698YcSjV7Nvj6wqpV/868KSIichmFG8mzgoJg5kxzqqnp0+Gzz4CKFc0JNgGGDYPffrO0RhERyXsUbiRPa9wYRo4013v3hnXrMIdRdehg3pZ65hlISLC0RhERyVsUbiTPGzQIHn8cUlOhbVs4dgz46CMoWRIOHIABA6wuUURE8hCFG8nzbDZzJHitWnD2LLRuDQkeQTBtmrnDJ5/A999bWqOIiOQdCjeSL/j6wqJFUKwY7NgBXbqA0fyef6/aPPfcP480FhGRgk7hRvKNUqVg/nxwd4dvvoH/+z9g1CioXt28pPP882AYVpcpIiIWU7iRfOWuu2DSJHN96FD4drGnOT2DhwcsXgyff25tgSIiYjlLw83PP//Mww8/TIkSJbDZbCxcuPC6+69ZswabzXbFEhUVlTsFS57w3HPQt6+53qkTbE+rbl7BAfM21bFj1hUnIiKWszTcJCQkULNmTT766KNMHbd//34iIyMdS/HixXOoQsmrxo2Dli3h4kVzZobIJ1+CRo3M2cO7ddPtKRGRAswtKwcdP34cm81GyZIlAdi0aRMzZ86kSpUqdO/e/abfp1WrVrRq1SrTn1+8eHECAwMzfZw4Dzc3mDMHGjaEffvg0cdcWfPpl3g1qGnOuDllinmJR0RECpwsXbl56qmnWL16NQBRUVHce++9bNq0icGDBzNixIhsLfBqatWqRWhoKPfeey/r16+/7r7JycnExsZmWMQ5BASYI8CDgswHFT839g6Mkf9nbuzfH44ft7ZAERGxRJbCza5du6hfvz4Ac+fOpVq1avz666/MmDGDqVOnZmd9GYSGhjJ58mS+/fZbvv32W8LCwmjWrBnbtm275jGjR48mICDAsYSFheVYfZL7ypc3R065uZlTNbyd+pJ5OSc2Frp31+0pEZECyGYYmf/bv1ChQuzatYsyZcrwyCOP0LhxY1577TWOHTtGxYoVSUxMzHwhNhsLFiygTZs2mTquadOmlCpViq+//vqq25OTk0lOTna8jo2NJSwsjJiYGPz9/TNdp+RNkyZBr17mPFQrvjjGPT3ugORk8/ZU165WlyciIrcoNjaWgICAm/r9naUrN1WrVmXy5Mn88ssvrFixgvvvvx+AU6dOUaRIkay8ZZbVr1+fgwcPXnO7p6cn/v7+GRZxPj16mA/2s9vhyVdLcWLAe+aGfv3g1CkrSxMRkVyWpXAzduxYPvnkE5o1a0aHDh2oWbMmAN99953jdlVu2bFjB6Ghobn6mZL32GzmZOGXpmh4fGUPUuo2Mm9PXRo3LiIiBUKWRks1a9aMc+fOERsbS1BQkKO9e/fu+Pj43PT7xMfHZ7jqcvjwYXbs2EHhwoUpVaoUgwYN4uTJk3z11VcATJgwgbJly1K1alWSkpL4/PPPWbVqFcuXL8/K1xAn4+0N334LderAxt9s9G+/iInbQ8xOOd9/Dw8/bHWJIiKSC7J05SYxMZHk5GRHsDl69CgTJkxg//79mXrmzJYtW6hduza1a9cGoH///tSuXZuhQ4cCEBkZybHLHsiWkpLCgAEDqF69Ok2bNmXnzp389NNPtGjRIitfQ5zQ7bfD9Onm+kdzijK91T8vevc2n4EjIiJOL0sdiu+77z7atm1Ljx49iI6OplKlSri7u3Pu3DneffddevbsmRO1ZovMdEiS/GvoUBg5Ery9DbYXjqDiyVXm7akJE6wuTUREsiDHOxRv27aNJk2aAPDNN98QHBzM0aNH+eqrr/jggw+y8pYi2WrYMGjRAhITbXT0mU8qbvDhh7B5s9WliYhIDstSuLl48SJ+fn4ALF++nLZt2+Li4kLDhg05evRothYokhWurjBtmvmAv60HAhhedZ45lKpbN0hNtbo8ERHJQVkKN+XLl2fhwoUcP36cH3/8kfvuuw+AM2fO6FaP5Bm33Qaffmquj97bmnV+rWDnTnj/fWsLExGRHJWlcDN06FBefvllypQpQ/369QkPDwfMqziXOgeL5AWPPWbOHG6323jGcw6x+MHw4Xr2jYiIE8tSh2Iw55SKjIykZs2auLiYGWnTpk34+/tTqVKlbC0yO6lDccETGws1a8KRI9C56A9MPfcQdOz477AqERHJ8zLz+zvL4eaSEydOADhmCM/rFG4Kpl9+gWbNzG4383icx/gG1q6Fu++2ujQREbkJOT5aym63M2LECAICAihdujSlS5cmMDCQkSNHYrfbs1S0SE5q0gQGDjTX+3h/TjQB8MILkJZmbWEiIpLtshRuBg8ezMSJExkzZgzbt29n+/btvPXWW3z44YcMGTIku2sUyRZDh0LFinA6MYBBnu/B77/D5MlWlyUiItksS7elSpQoweTJk3nkkUcytC9atIhevXpx8uTJbCswu+m2VMG2dq15ewrgV8IJD9wH+/dDJp6sLSIiuS/Hb0udP3/+qp2GK1WqxPnz57PyliK5omlT6NrVXO/u9RWp0fHw+uvWFiUiItkqS+GmZs2aTJw48Yr2iRMnUqNGjVsuSiQnvfMOFC0Ku5Iq8C794YsvYOtWq8sSEZFskqXbUmvXruXBBx+kVKlSjmfcbNiwgePHj7NkyRLH1Ax5kW5LCcBXX0HnzuDtmszu9EqUbV4WVq4Em83q0kRE5Cpy/LZU06ZN+fPPP3n00UeJjo4mOjqatm3bsnv3br7++ussFS2Sm555Bpo3h8R0T3rZJmOsXg1Ll1pdloiIZINbfs7N5Xbu3Mmdd95Jenp6dr1lttOVG7nkzz+henVISYGFtKZ11b9gxw5wc7O6NBER+Y8cv3Ij4gzuuAMGDDDXX3UZT+ru/eZsmyIikq8p3EiBNnCgOQr8T3t5JtMDhgyBhASryxIRkVugcCMFmr8/jBhhrr/pMoILkYnw3nvWFiUiIrckU31u2rZte93t0dHRrF27Vn1uJF9JSzMn1tyzBwYwjnGFhsPBgxAcbHVpIiLyjxzrcxMQEHDdpXTp0nTq1OmWihfJbW5uMH68uf6BrS9/xRf/93KOiIjkO9k6Wio/0JUbuZaWLWH5cniMecxz72hevSlVyuqyREQEjZYSyZJx48DFBb7hcdan1oNRo6wuSUREskDhRuQf1avDc8+Z6y8zDuOLKXD4sLVFiYhIpinciFxmxAjw9oaNhPN9eitdvRERyYcUbkQuExICffua64MZhf3LafDXX9YWJSIimaJwI/Ifr74KAQGwi+rMsj8BI0daXZKIiGSCwo3IfwQFmQEHYCgjSP1qFhw4YG1RIiJy0xRuRK6ib19zWoZDlOMLo6ueeyMiko8o3Ihcha8vvPGGuT6CoSTOmA/79llblIiI3BSFG5Fr6N4dSpeGSEow0egFb71ldUkiInITFG5ErsHTE95801wfw0BiZiw2n1osIiJ5msKNyHU88wxUrgznKcJ4ez8YPdrqkkRE5AYUbkSuw9X135Hg79KfM9OWwpEjltYkIiLXp3AjcgNt20LdupBAId5KfxXGjrW6JBERuQ6FG5EbsNn+7Us8iZ4c/eInOHHC2qJEROSaFG5EbkJEBDRvDil4Mjx1ELz9ttUliYjINSjciNyEy6/eTKMzez/5GaKirC1KRESuSuFG5CY1bAitWxvYcWVIyhswbpzVJYmIyFUo3Ihkwv/9nw2bzeBbHmPLxI26eiMikgcp3IhkQrVq0LGjuT4oeZieWiwikgcp3Ihk0ogRNtzd7PzEvSyf9BccO2Z1SSIichmFG5FMKlsWeve2AfBq2ijsI0dZXJGIiFxO4UYkC94YYiOgUBo7qcWML5I055SISB6icCOSBUWKwKA33AAYbIwkaaj63oiI5BUKNyJZ9OKLUDI4heOU4sNZRWHPHqtLEhERFG5EsszbG/5vrAcAo3idvwe+Y3FFIiICCjcit+Tpp6HGHYnEEMhb31eDrVutLklEpMBTuBG5Ba6u8PYH3gBMpA+H/zcGDMPiqkRECjaFG5FbdN99ENEkiRQ8Gbj1MZgxw+qSREQKNIUbkVtks8G4D72w2Qzm0p71fedCbKzVZYmIFFiWhpuff/6Zhx9+mBIlSmCz2Vi4cOENj1mzZg133nknnp6elC9fnqlTp+Z4nSI3UrMmPNfFDsBL59/APnykxRWJiBRcloabhIQEatasyUcffXRT+x8+fJgHH3yQ5s2bs2PHDvr168fzzz/Pjz/+mMOVitzYyLdcKeSdxmbqM2vCadi71+qSREQKJJth5I3ejzabjQULFtCmTZtr7vPaa6/xww8/sGvXLkfbk08+SXR0NMuWLbupz4mNjSUgIICYmBj8/f1vtWyRDN56CwYPhpIcZ3/znvis/N68byUiIrckM7+/81Wfmw0bNhAREZGhrWXLlmzYsOGaxyQnJxMbG5thEckpL70EpUqkcoIwxq+uDfPnW12SiEiBk6/CTVRUFMHBwRnagoODiY2NJTEx8arHjB49moCAAMcSFhaWG6VKAeXtDWPHuwMwhoGcemG0OheLiOSyfBVusmLQoEHExMQ4luPHj1tdkji59u0hvEE6F/FlcGRvePllq0sSESlQ8lW4CQkJ4fTp0xnaTp8+jb+/P97e3lc9xtPTE39//wyLSE6y2eC9910BmEpXNn22A5Yvt7YoEZECJF+Fm/DwcFauXJmhbcWKFYSHh1tUkcjVNWgAnTub6735CPtz3XR7SkQkl1gabuLj49mxYwc7duwAzKHeO3bs4NixY4B5S6lTp06O/Xv06MGhQ4d49dVX2bdvHx9//DFz587lpZdesqJ8kesaMwb8/Q22UI8pJ+7V7SkRkVxiabjZsmULtWvXpnbt2gD079+f2rVrM3ToUAAiIyMdQQegbNmy/PDDD6xYsYKaNWsyfvx4Pv/8c1q2bGlJ/SLXExICw4ebw8AHMobzn32j21MiIrkgzzznJrfoOTeSm1JToXZt2L0bejORiWFvw65doD97IiKZ4rTPuRHJb9zd4cMPzfVJ9GTH8cK6PSUiksMUbkRyWPPm5vBwO670YSLGZ5/p9pSISA5SuBHJBePGgY8PrOcuvuYZeP55jZ4SEckhCjciuaBkSRgyxFx/2eU9LhyP0+0pEZEconAjkkv694fKleGsvQiDGA26PSUikiMUbkRyiYcHTJpkrn9KdzbSwLw9FRNjbWEiIk5G4UYkFzVtaj652MCFHh5TSDt+SrenRESymcKNSC575x0ICoKdKVX4kBfg8891e0pEJBsp3IjksmLF4O23zfWh7qM5wW3QrRvExVlbmIiIk1C4EbHAs89CeDjEp3rR1+dzOHYMXn3V6rJERJyCwo2IBVxcYPJkcHWF+RfvZxktzYZVq6wuTUQk31O4EbFIjRrQt6+53sf/K5LwhOeeg/h4awsTEcnnFG5ELDRsGISGwl+xxXknYBQcOQIDB1pdlohIvqZwI2Ihf394911z/a3EfhymDHz0Eaxda2ldIiL5mcKNiMXatzcn10xKcaVvqYVmY5cumntKRCSLFG5ELGazmRdr3Nzg+2M1+b74c+btqZdesro0EZF8SeFGJA+oXNmcewrgRZeJJOINU6bAd99ZW5iISD6kcCOSRwwZYs4efiTKi9ENF5mN3brB2bPWFiYiks8o3IjkEYUKwXvvmetjt0VwoMIDcOYMdO8OhmFtcSIi+YjCjUge0q4d3HcfpKTYeKHYLAw3d1i4EKZNs7o0EZF8Q+FGJA+x2WDiRPDwgB9/9Wd++znmhhdfNDsZi4jIDSnciOQxFSr8O81Uv7VtiG8YYU6q+cwzkJ5ubXEiIvmAwo1IHjRoEJQpAydO2BhZYx74+cG6df9OJy4iItekcCOSB/n4wIcfmuvvTglkz8CvzBdDh8KWLdYVJiKSDyjciORRDz0EjzwCaWnQe0VrjMceN1907AgJCVaXJyKSZynciORh778P3t6wZo2NqXdPgRIl4M8/4ZVXrC5NRCTPUrgRycPKlIHhw831l4YU4tT4WeaLSZNg8WLL6hIRycsUbkTyuJdegnr1ICYGesy8G+Olf+Zp6NoVTp2ytjgRkTxI4UYkj3NzM6eZcneH77+H2bXGQO3acO4cPP20hoeLiPyHwo1IPlCtmjn3FMAL/d0589E88PWF1ath9GhrixMRyWMUbkTyiYEDoUYN+PtvePH9cvDxx+aGYcPgl1+sLU5EJA9RuBHJJ9zdzdtTrq4wZw4s8OtkPrXYboennoLz560uUUQkT1C4EclH6tT5d2qG7t3h1Bsfm/M1nDgBzz6r2cNFRFC4Ecl3hg2DWrXM/sTP9CxE+ozZ5kybixZpegYRERRuRPIdT0+YPducomHVKnj7pzthwgRz46BBsGSJpfWJiFhN4UYkH6pYESZONNeHDIGNtXpAt27mbakOHWD/fmsLFBGxkMKNSD7VpQs8+aT5mJsOT9mIGTUR7roLYmPNSamio60uUUTEEgo3IvmUzQaTJ0PZsnDkCPzvBQ+Med9AWJg5/9RTT+kBfyJSICnciORjAQEwa5b5FOM5c+CDOcGwcKE52+bSpWYfHBGRAkbhRiSfa9AAxo411/v3h2Vn7jQfiAPwzjvwxRfWFSciYgGFGxEn8NJL5jyadju0bw97ajxpjhkH6NHDHFYlIlJAKNyIOAGbDSZNgiZNzP7EDz8M53oPM0dOpaVBu3awb5/VZYqI5AqFGxEn4ekJ335rdjA+dAgee9xGyuQp0LixOXLqwQfh7FmryxQRyXEKNyJOpFgx+P578PODtWuh+4te2L9dALffbiaeNm0gKcnqMkVEcpTCjYiTqVrVHDnl4gLTpsGLI4thLP7BHFr166+ag0pEnJ7CjYgTatUKpk41++J89BG8OqUSxrfzzTHjs2b929lYRMQJKdyIOKlnnjEf8gcwbhy8+fM98MknZsPIkeZlHRERJ6RwI+LEuneH998310eMgDFnnoXXXzcbunWD1autK05EJIfkiXDz0UcfUaZMGby8vGjQoAGbNm265r5Tp07FZrNlWLy8vHKxWpH85cUXYcwYc33QIPig+EjzYTipqdC2rYaIi4jTsTzczJkzh/79+zNs2DC2bdtGzZo1admyJWfOnLnmMf7+/kRGRjqWo0eP5mLFIvnPa6/B0KHmet9+LnzR7GsIDzeHiD/wAERGWlqfiEh2sjzcvPvuu3Tr1o2uXbtSpUoVJk+ejI+PD1MuPT7+Kmw2GyEhIY4lODg4FysWyZ/efBMGDDDXu/VyZ2anZVCuHBw+DPffr1nERcRpWBpuUlJS2Lp1KxEREY42FxcXIiIi2LBhwzWPi4+Pp3Tp0oSFhdG6dWt27959zX2Tk5OJjY3NsIgURDabOdVUz57mSPBOffxZMGAdhITA77+bjzVOTLS6TBGRW2ZpuDl37hzp6elXXHkJDg4mKirqqsdUrFiRKVOmsGjRIqZPn47dbqdRo0acOHHiqvuPHj2agIAAxxIWFpbt30Mkv7DZYOJE6NIF0tOhfd8Qlg1dbz4DZ906sy9OWprVZYqI3BLLb0tlVnh4OJ06daJWrVo0bdqU+fPnU6xYMT65NMT1PwYNGkRMTIxjOX78eC5XLJK3uLjA55/DE0+YfYof7X87a0b8DF5e5uONn3/enIFTRCSfsjTcFC1aFFdXV06fPp2h/fTp04SEhNzUe7i7u1O7dm0OHjx41e2enp74+/tnWEQKOldXmD7dvBOVlAQPvV6DjSOWmxumTTM75+gpxiKST1kabjw8PKhTpw4rV650tNntdlauXEl4ePhNvUd6ejp//PEHoaGhOVWmiFNyd4e5cyEiAhISoNVbTdgxdL65ccIEPcVYRPIty29L9e/fn88++4xp06axd+9eevbsSUJCAl27dgWgU6dODBo0yLH/iBEjWL58OYcOHWLbtm08/fTTHD16lOeff96qryCSb3l5wcKF/04cft/ER9g7eLq5ceRIsweyiEg+42Z1Ae3bt+fs2bMMHTqUqKgoatWqxbJlyxydjI8dO4aLy78Z7MKFC3Tr1o2oqCiCgoKoU6cOv/76K1WqVLHqK4jka76+8MMP0KIFbN0KEV92ZO2AOMqP7wmvvgqFCplDrERE8gmbYRSsG+uxsbEEBAQQExOj/jcil/n7b2jWDHbtMkeHL3/oA6p/3tfcOG0adOpkaX0iUrBl5ve35belRCRvKFIEfvoJatSAqCho+u0LbHpinLmxa1ezB7KISD6gcCMiDsHBsGYNNGwIFy7YaLGkP6sfHGcODe/UCb780uoSRURuSOFGRDIICoIVK8w+OPHxNlr91J/v7v/YHBr+7LPw2WdWlygicl0KNyJyhUKFYPFiaN0akpNtPLq8BxOafIsB0L07fPyx1SWKiFyTwo2IXJWXF3zzjXmxxm638dIvbXmu6m8k4wG9e8PYsXrQn4jkSQo3InJNbm7mVA3vvWdO2/Dl7vrcc9t+TlMcBg40r+KkplpdpohIBgo3InJdNhv06wdLl0JgIPx6sgx1Aw+y2VbfTD6tWsGFC1aXKSLioHAjIjflvvvgt9+gYkU4Ee1HI5cNvO0+GPvKVdCoEfz1l9UliogACjcikgl33AEbN8Ljj0Nauguvpf4f93r+zMl9sdCgAfz8s9Uliogo3IhI5gQGwpw58MUX4OMDq5Lvoobrbhb+fZc5fvzzz60uUUQKOIUbEck0m80cRbVtG9x5J5xPD+RRFtI7bQKJ3V4wO+mkpVldpogUUAo3IpJlFSvChg3w8svm64/pTQN+Y8/7y+GBB9TRWEQsoXAjIrfEwwPeeQeWLYPixeEPalCXLXy2ojRGvfqwe7fVJYpIAaNwIyLZomVL2LkT7r0XEvGhO5/R7q+xnKn/kPk0QBGRXKJwIyLZJiTEvILz9tvg5mawgLZUvbiJbx+fBYMGQXq61SWKSAGgcCMi2crFBV55BTZvtlGjusE5ivEY3/LUmOqcv7c9REVZXaKIODmFGxHJEbVqwabNNl5/HVxsdmbxFFVXf8j8Cq/B7Nmal0pEcozCjYjkGE9PGDUKNmx0oVLZJKIIpV38NNp1cOfUQ93hzBmrSxQRJ6RwIyI5rn592L7Hi8ED03FzSWc+7aiy5B0+Kzca+4xZuoojItlK4UZEcoWXF/zfaFe2bnelXtUEYgike/x7NHv6NnbX7wq//251iSLiJBRuRCRX1agBG3b68t47afi4p/ALd1Nry2cMrLmUhB4D4Px5q0sUkXxO4UZEcp2rK/R72Y09Bzxofd9F0nBnLK9R9ZMX+K7Mi/DBB5CSYnWZIpJPKdyIiGVKl4aFP/qwaBGUKp7EUcrQOm46LftW5I9yrc0ZOu12q8sUkXxG4UZELPfII7DnkBevvWLH3TWd5bSk1onFdHsylqg7H4CVK9XpWERumsKNiOQJvr4w5m0X9u53pV3rNOy48jndKL/zG4ZGrOds4zawdq3VZYpIPqBwIyJ5Srly8M1CN375BerXTiWBQoxkKKU2zKZnsz38Gd4Z1q2zukwRycMUbkQkT7rrLtiwxZ25c6FujRSS8GYyPam08UvaNDnH6jsHYKxeo9tVInIFhRsRybNcXODxx2HTDg/WroWHIy5i4MIi2nDP9vFUv6cokyuMJ/67VQo5IuKgcCMieZ7NBnffDd+t8GHPHujxdBy+bsnspho9/3qZ21rXoW/IHPZPWAppaVaXKyIWsxlGwfrnTmxsLAEBAcTExODv7291OSKSRTExMO39aCa+l8KB6OKO9vu8fqbP09E88E5zXAP9LKxQRLJTZn5/68qNiORLAQHw4tBA9v1dnGWzo3n4jv3YsLM86W4e+fwRyhc+z9i7f+Dc1qNWlyoiuUzhRkTyNRcXaNk+kO/2V+SvPSm8cu8OCrtc4IhRmoG/PEjJusF0ClvNbxM3Y9gL1IVqkQJLt6VExOkkJtiZPfh3PvrSh62xdzjaa3nu4ZmIKJ4cXpkSdUItrFBEMiszv78VbkTEqW2ed4SPhkYxe18tkvECwIV07im8k46PJfPosBoElPC1uEoRuRGFm+tQuBEpmP4+EsfcN35nxvd+rI+t4Wj3IJn7Qn7n8dYpPDKoGoGlAyysUkSuReHmOhRuROTwmqPMHHGQGetKsTe1gqPdnRQiiu7gwRbJtOpXkdsbFr/Ou4hIblK4uQ6FGxFxMAz2LNjPvA8imbexJLuTK2TYXNHrKK3qnOG+Z4Jp8lQYhfxsFhUqIgo316FwIyLXsnfJYb6feIQl6wJYH1edNNwd29xIpX7wUe5pksY9nUrSMKIQ3t4WFitSwCjcXIfCjYjcjJh9kfz07u8sXWKw6mRFDlM2w3Z3Wyr1bztJ0yZ2mj5Zgkb3eFGokEXFihQACjfXoXAjIpl28SKH525m9YxTrPrNl9VxdTjFbRl2cbOlUTf0FM3vSqHZk6E0utdXYUckGyncXIfCjYjcKuPoMQ7N3cLahRdYuyOAtRfrcpQyGfZxI5WaxU7RsEYiDVsG0LBNCOXK27Cp245IlijcXIfCjYhkK8OAQ4c4Mn8ba76LZc3OQFbH1eUYpa/YNcgtjpolzlKrhp2azYKo2bwwlavY8PKyoG6RfEbh5joUbkQkx0VGcmzhVjYuucDGbe5sjCzDVqM2KXhesasL6ZQNOE+V0hepXN2NKo0DqVzHl0qVQH9FifxL4eY6FG5EJNelpJC8+Xf2/HCYnevi2LnXgx1/l2SnUYMLFL7mYSV8o6l8WxwV7zCoUMuHCvWCqFDJlbJlwd39moeJOCWFm+tQuBGRPCEpCeP3Pzjz60H2/BrNnl129hwrxN6EMPZSmSiuPfeVqy2dUn4XKBecQLmy6ZSr7EnZWv6UqVqI0mVsFC2K+vaI01G4uQ6FGxHJ02JjYf9+orccZN/GaPb+kcaB414cOF+YP+3lOUh5LnL9ubB8XJMo7XeBkkUSKRmaTskybpSs4E2JSv6E3O5DcDAEB4OHRy59J5FsoHBzHQo3IpIvpafDiRMYfx4gcusp/vrjIn8dNDh0woO//g7kSHIIRyhzxRD16wnyiCfYN57iAckUL5JO8WAbxULdKR7mSbEyPhQr5UOx4jaKFYPChcHNLQe/n8gNKNxch8KNiDilxEQ4fpzkA8c4vvM8R/Zc5OSxdE5EunLiby+OxwYSlV6UKEI4TXCGpy/frCD3OIp6J1DEN5nC/qkEBRgULgxBRV0JLOZOYHEPAoK9CAj1IbCYO/7+OBYvL90qk1ujcHMdCjciUmDFx0NkJPaTkZw/8DdRB+M5eyKZM6fSOHsWTp9352ycF2cTC3EmvTBnKcYZil+30/PNcrOl4eeWiJ97Mv5eyfh5peLnnU4hHzuFfA0KFYJCflDIzwXfAFcKBbjhG+iOb5AHvoU98QnyxDfADR8fHIu3t0JTQZLvws1HH33EO++8Q1RUFDVr1uTDDz+kfv3619x/3rx5DBkyhCNHjlChQgXGjh3LAw88cFOfpXAjInITEhPh77/h7FnSzl7gwrE4zh1P5NypFM6dTufCeYML0TbOx7pyPt6TmCRPYlK8iU4vRAwBxBBALP7E4YeBS46VacOOl0sK3i4peLul4O2aird7Kl5u6Xi5p+PlkY6Xhx0vDwNPTwNPD/DyNPD0Ak9PG55e5uLh5YKnt7lcWvfwdv138XG7YnH3dMHDwxy5dmm59Nol575ygZWZ39+W30GdM2cO/fv3Z/LkyTRo0IAJEybQsmVL9u/fT/Hixa/Y/9dff6VDhw6MHj2ahx56iJkzZ9KmTRu2bdtGtWrVLPgGIiJOyNsbSpaEkiVxA4r9s9xQWprZKTomBmKPYI+OJeFMArFnkoj7O5nYv9OIi043l1iD+ASbuSS6EpfoRnyyOwmp7iSkepCQ5klCuhcJ+HIRHxLwJQFfEvEmFbM3tIELiXYvEu1ekJaD5yOTXEjHzZaOuy3N8dPdlo6bSzpuNjvuLv+su9gvWwzzp+s/6652XF247KeBq6th/nQBV1dzcXMzHOvmYvvnp3HZOri62XB1AxcX86erqw2Xf7a7uNnMfd3MNhdXcHVz+Xd7hm02XN1dHOuOxc0FFxdzX7/C7lRpelN/YnKE5VduGjRoQL169Zg4cSIAdrudsLAwXnjhBQYOHHjF/u3btychIYHFixc72ho2bEitWrWYPHnyDT9PV25ERPIRw4CUFLh40byalJAAiYmkxSWSGJvKxegULsakkhiXRmJ8OknxaSQm2ElMsJOcaCcp0SApCZKSIDkZklJsJKe4kJxiIznVheQ0V5LTXEhOcyM53ZWUdDdS7ObPZLs7yYY7qYYbKYY7KXiQjCepmOv//tSws/8KL/QHv8ZVz9b3zDdXblJSUti6dSuDBg1ytLm4uBAREcGGDRuuesyGDRvo379/hraWLVuycOHCq+6fnJxMcnKy43VsbOytFy4iIrnDZgNPT3MJCnI0uwF+/yy5wjDMEWspKZCa+s+SBKmpGMkppCWlkZr4z5KUTlpyOqlJ6aQm28315HTSku2kpdpJTTZIS7GTmmInPdUgLdUgLQ1Sk+2kp+N4fennpbb0dEhLt2X4mWHdDunpNtLsNtLTbaQbNtLtNux282e6/VKbi9lu/Pv60rr503ydcd0FO5dem+uXtxnYSDdczXZcCPW6kFv/Za7K0nBz7tw50tPTCQ4OztAeHBzMvn37rnpMVFTUVfePioq66v6jR49m+PDh2VOwiIgUTDabORb+KuPhbYD7P4tcUsbST3f6Lk+DBg0iJibGsRw/ftzqkkRERCQHWXrlpmjRori6unL69OkM7adPnyYkJOSqx4SEhGRqf09PTzw9r5ysTkRERJyTpVduPDw8qFOnDitXrnS02e12Vq5cSXh4+FWPCQ8Pz7A/wIoVK665v4iIiBQslg8F79+/P507d6Zu3brUr1+fCRMmkJCQQNeuXQHo1KkTt912G6NHjwagb9++NG3alPHjx/Pggw8ye/ZstmzZwqeffmrl1xAREZE8wvJw0759e86ePcvQoUOJioqiVq1aLFu2zNFp+NixY7hc9jSkRo0aMXPmTN544w1ef/11KlSowMKFC/WMGxEREQHywHNucpuecyMiIpL/ZOb3t9OPlhIREZGCReFGREREnIrCjYiIiDgVhRsRERFxKgo3IiIi4lQUbkRERMSpKNyIiIiIU1G4EREREadi+ROKc9ulZxbGxsZaXImIiIjcrEu/t2/m2cMFLtzExcUBEBYWZnElIiIikllxcXEEBARcd58CN/2C3W7n1KlT+Pn5YbPZsvW9Y2NjCQsL4/jx45raIYfpXOcenevco3Ode3Suc092nWvDMIiLi6NEiRIZ5py8mgJ35cbFxYWSJUvm6Gf4+/vrf5ZconOde3Suc4/Ode7Ruc492XGub3TF5hJ1KBYRERGnonAjIiIiTkXhJht5enoybNgwPD09rS7F6elc5x6d69yjc517dK5zjxXnusB1KBYRERHnpis3IiIi4lQUbkRERMSpKNyIiIiIU1G4EREREaeicJNNPvroI8qUKYOXlxcNGjRg06ZNVpeU740ePZp69erh5+dH8eLFadOmDfv378+wT1JSEr1796ZIkSIUKlSIdu3acfr0aYsqdh5jxozBZrPRr18/R5vOdfY5efIkTz/9NEWKFMHb25vq1auzZcsWx3bDMBg6dCihoaF4e3sTERHBgQMHLKw4f0pPT2fIkCGULVsWb29vypUrx8iRIzPMTaRznXU///wzDz/8MCVKlMBms7Fw4cIM22/m3J4/f56OHTvi7+9PYGAgzz33HPHx8bdenCG3bPbs2YaHh4cxZcoUY/fu3Ua3bt2MwMBA4/Tp01aXlq+1bNnS+PLLL41du3YZO3bsMB544AGjVKlSRnx8vGOfHj16GGFhYcbKlSuNLVu2GA0bNjQaNWpkYdX536ZNm4wyZcoYNWrUMPr27eto17nOHufPnzdKly5tdOnSxfjtt9+MQ4cOGT/++KNx8OBBxz5jxowxAgICjIULFxo7d+40HnnkEaNs2bJGYmKihZXnP6NGjTKKFCliLF682Dh8+LAxb948o1ChQsb777/v2EfnOuuWLFliDB482Jg/f74BGAsWLMiw/WbO7f3332/UrFnT2Lhxo/HLL78Y5cuXNzp06HDLtSncZIP69esbvXv3drxOT083SpQoYYwePdrCqpzPmTNnDMBYu3atYRiGER0dbbi7uxvz5s1z7LN3714DMDZs2GBVmflaXFycUaFCBWPFihVG06ZNHeFG5zr7vPbaa8Zdd911ze12u90ICQkx3nnnHUdbdHS04enpacyaNSs3SnQaDz74oPHss89maGvbtq3RsWNHwzB0rrPTf8PNzZzbPXv2GICxefNmxz5Lly41bDabcfLkyVuqR7elblFKSgpbt24lIiLC0ebi4kJERAQbNmywsDLnExMTA0DhwoUB2Lp1K6mpqRnOfaVKlShVqpTOfRb17t2bBx98MMM5BZ3r7PTdd99Rt25dHn/8cYoXL07t2rX57LPPHNsPHz5MVFRUhnMdEBBAgwYNdK4zqVGjRqxcuZI///wTgJ07d7Ju3TpatWoF6FznpJs5txs2bCAwMJC6des69omIiMDFxYXffvvtlj6/wE2cmd3OnTtHeno6wcHBGdqDg4PZt2+fRVU5H7vdTr9+/WjcuDHVqlUDICoqCg8PDwIDAzPsGxwcTFRUlAVV5m+zZ89m27ZtbN68+YptOtfZ59ChQ0yaNIn+/fvz+uuvs3nzZl588UU8PDzo3Lmz43xe7e8UnevMGThwILGxsVSqVAlXV1fS09MZNWoUHTt2BNC5zkE3c26joqIoXrx4hu1ubm4ULlz4ls+/wo3kC71792bXrl2sW7fO6lKc0vHjx+nbty8rVqzAy8vL6nKcmt1up27durz11lsA1K5dm127djF58mQ6d+5scXXOZe7cucyYMYOZM2dStWpVduzYQb9+/ShRooTOtZPTbalbVLRoUVxdXa8YNXL69GlCQkIsqsq59OnTh8WLF7N69WpKlizpaA8JCSElJYXo6OgM++vcZ97WrVs5c+YMd955J25ubri5ubF27Vo++OAD3NzcCA4O1rnOJqGhoVSpUiVDW+XKlTl27BiA43zq75Rb98orrzBw4ECefPJJqlevzjPPPMNLL73E6NGjAZ3rnHQz5zYkJIQzZ85k2J6Wlsb58+dv+fwr3NwiDw8P6tSpw8qVKx1tdrudlStXEh4ebmFl+Z9hGPTp04cFCxawatUqypYtm2F7nTp1cHd3z3Du9+/fz7Fjx3TuM6lFixb88ccf7Nixw7HUrVuXjh07OtZ1rrNH48aNr3ikwZ9//knp0qUBKFu2LCEhIRnOdWxsLL/99pvOdSZdvHgRF5eMv+ZcXV2x2+2AznVOuplzGx4eTnR0NFu3bnXss2rVKux2Ow0aNLi1Am6pO7IYhmEOBff09DSmTp1q7Nmzx+jevbsRGBhoREVFWV1avtazZ08jICDAWLNmjREZGelYLl686NinR48eRqlSpYxVq1YZW7ZsMcLDw43w8HALq3Yel4+WMgyd6+yyadMmw83NzRg1apRx4MABY8aMGYaPj48xffp0xz5jxowxAgMDjUWLFhm///670bp1aw1PzoLOnTsbt912m2Mo+Pz5842iRYsar776qmMfneusi4uLM7Zv325s377dAIx3333X2L59u3H06FHDMG7u3N5///1G7dq1jd9++81Yt26dUaFCBQ0Fz0s+/PBDo1SpUoaHh4dRv359Y+PGjVaXlO8BV12+/PJLxz6JiYlGr169jKCgIMPHx8d49NFHjcjISOuKdiL/DTc619nn+++/N6pVq2Z4enoalSpVMj799NMM2+12uzFkyBAjODjY8PT0NFq0aGHs37/fomrzr9jYWKNv375GqVKlDC8vL+P22283Bg8ebCQnJzv20bnOutWrV1/17+jOnTsbhnFz5/bvv/82OnToYBQqVMjw9/c3unbtasTFxd1ybTbDuOxRjSIiIiL5nPrciIiIiFNRuBERERGnonAjIiIiTkXhRkRERJyKwo2IiIg4FYUbERERcSoKNyIiIuJUFG5EpECy2WwsXLjQ6jJEJAco3IhIruvSpQs2m+2K5f7777e6NBFxAm5WFyAiBdP999/Pl19+maHN09PTompExJnoyo2IWMLT05OQkJAMS1BQEGDeMpo0aRKtWrXC29ub22+/nW+++SbD8X/88Qf33HMP3t7eFClShO7duxMfH59hnylTplC1alU8PT0JDQ2lT58+GbafO3eORx99FB8fHypUqMB3333n2HbhwgU6duxIsWLF8Pb2pkKFCleEMRHJmxRuRCRPGjJkCO3atWPnzp107NiRJ598kr179wKQkJBAy5YtCQoKYvPmzcybN4+ffvopQ3iZNGkSvXv3pnv37vzxxx989913lC9fPsNnDB8+nCeeeILff/+dBx54gI4dO3L+/HnH5+/Zs4elS5eyd+9eJk2aRNGiRXPvBIhI1t3y1JsiIpnUuXNnw9XV1fD19c2wjBo1yjAMc0b4Hj16ZDimQYMGRs+ePQ3DMIxPP/3UCAoKMuLj4x3bf/jhB8PFxcWIiooyDMMwSpQoYQwePPiaNQDGG2+84XgdHx9vAMbSpUsNwzCMhx9+2OjatWv2fGERyVXqcyMilmjevDmTJk3K0Fa4cGHHenh4eIZt4eHh7NixA4C9e/dSs2ZNfH19HdsbN26M3W5n//792Gw2Tp06RYsWLa5bQ40aNRzrvr6++Pv7c+bMGQB69uxJu3bt2LZtG/fddx9t2rShUaNGWfquIpK7FG5ExBK+vr5X3CbKLt7e3je1n7u7e4bXNpsNu90OQKtWrTh69ChLlixhxYoVtGjRgt69ezNu3Lhsr1dEspf63IhInrRx48YrXleuXBmAypUrs3PnThISEhzb169fj4uLCxUrVsTPz48yZcqwcuXKW6qhWLFidO7cmenTpzNhwgQ+/fTTW3o/EckdunIjIpZITk4mKioqQ5ubm5uj0+68efOoW7cud911FzNmzGDTpk188cUXAHTs2JFhw4bRuXNn3nzzTc6ePcsLL7zAM888Q3BwMABvvvkmPXr0oHjx4rRq1Yq4uDjWr1/PCy+8cFP1DR06lDp16lC1alWSk5NZvHixI1yJSN6mcCMilli2bBmhoaEZ2ipWrMi+ffsAcyTT7Nmz6dWrF6GhocyaNYsqVaoA4OPjw48//kjfvn2pV68ePj4+tGvXjnfffdfxXp07dyYpKYn33nuPl19+maJFi/LYY4/ddH0eHh4MGjSII0eO4O3tTZMmTZg9e3Y2fHMRyWk2wzAMq4sQEbmczWZjwYIFtGnTxupSRCQfUp8bERERcSoKNyIiIuJU1OdGRPIc3S0XkVuhKzciIiLiVBRuRERExKko3IiIiIhTUbgRERERp6JwIyIiIk5F4UZEREScisKNiIiIOBWFGxEREXEqCjciIiLiVP4f+2JdzxexfMsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class SelfAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        feature_dim = input_shape[-1]\n",
    "        # Weight matrices for Q, K, V\n",
    "        self.Wq = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wq')\n",
    "        self.Wk = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wk')\n",
    "        self.Wv = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wv')\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Linear projections\n",
    "        q = K.dot(inputs, self.Wq)  # Query\n",
    "        k = K.dot(inputs, self.Wk)  # Key\n",
    "        v = K.dot(inputs, self.Wv)  # Value\n",
    "\n",
    "        # Scaled Dot-Product Attention\n",
    "        scores = K.batch_dot(q, k, axes=[2, 2])  # (batch, seq_len, seq_len)\n",
    "        scores = scores / K.sqrt(K.cast(K.shape(k)[-1], dtype=K.floatx()))  # Scale\n",
    "        attention_weights = K.softmax(scores, axis=-1)  # Normalize\n",
    "\n",
    "        # Weighted sum of values\n",
    "        output = K.batch_dot(attention_weights, v)  # (batch, seq_len, feature_dim)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "encoder_inputs = Input(shape=(max_input_length,))\n",
    "encoder_embedding = Embedding(input_vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(max_output_length - 1,), name=\"decoder_inputs\")\n",
    "decoder_embedding = Embedding(output_vocab_size, 256, name=\"decoder_embedding\")(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True, name=\"decoder_lstm\")\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "\n",
    "attention = AdditiveAttention(name=\"attention_layer\")\n",
    "attention_output = attention([decoder_outputs, encoder_outputs])\n",
    "\n",
    "decoder_concat = Concatenate(axis=-1, name=\"concat_layer\")([decoder_outputs, attention_output])\n",
    "\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax', name=\"output_dense\")\n",
    "decoder_outputs = decoder_dense(decoder_concat)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history_he = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'], label=\"glorot_uniform\", color='red')\n",
    "plt.plot(history_he.history['loss'], label=\"he_uniform\", color='blue')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <b>here</b> for the solution.\n",
    "\n",
    "<!-- Your answer is below:\n",
    "\n",
    "\n",
    "#Define the Self-Attention Layer\n",
    "class SelfAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        feature_dim = input_shape[-1]\n",
    "        # Weight matrices for Q, K, V\n",
    "        self.Wq = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wq')\n",
    "        self.Wk = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wk')\n",
    "        self.Wv = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wv')\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Linear projections\n",
    "        q = K.dot(inputs, self.Wq)  # Query\n",
    "        k = K.dot(inputs, self.Wk)  # Key\n",
    "        v = K.dot(inputs, self.Wv)  # Value\n",
    "\n",
    "        # Scaled Dot-Product Attention\n",
    "        scores = K.batch_dot(q, k, axes=[2, 2])  # (batch, seq_len, seq_len)\n",
    "        scores = scores / K.sqrt(K.cast(K.shape(k)[-1], dtype=K.floatx()))  # Scale\n",
    "        attention_weights = K.softmax(scores, axis=-1)  # Normalize\n",
    "\n",
    "        # Weighted sum of values\n",
    "        output = K.batch_dot(attention_weights, v)  # (batch, seq_len, feature_dim)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    \n",
    "#Encoder\n",
    "encoder_inputs = Input(shape=(max_input_length,))\n",
    "encoder_embedding = Embedding(input_vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "#Decoder\n",
    "decoder_inputs = Input(shape=(max_output_length - 1,), name=\"decoder_inputs\")\n",
    "decoder_embedding = Embedding(output_vocab_size, 256, name=\"decoder_embedding\")(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True, name=\"decoder_lstm\")\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "\n",
    "#Attention Mechanism\n",
    "attention = AdditiveAttention(name=\"attention_layer\")\n",
    "attention_output = attention([decoder_outputs, encoder_outputs])\n",
    "\n",
    "# Concatenate context with decoder outputs\n",
    "decoder_concat = Concatenate(axis=-1, name=\"concat_layer\")([decoder_outputs, attention_output])\n",
    "\n",
    "# Final Dense Layer\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax', name=\"output_dense\")\n",
    "decoder_outputs = decoder_dense(decoder_concat)\n",
    "\n",
    "#Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Step 6: Train the Model\n",
    "history_he = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)\n",
    "\n",
    "#Plotting training losses for glorot_uniform and he_uniform inititalizers\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'], label=\"glorot_uniform\", color='red')\n",
    "plt.plot(history_he.history['loss'], label=\"he_uniform\", color='blue')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice excercise 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practice exercise, try to use adaptive gradient optimizer instead of adam. Then, plot and compare the results between adam and adaptive gradient optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.0095\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Write your answer here\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Step 6: Train the Model\n",
    "history_adagrad = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)\n",
    "\n",
    "#Plotting training losses for glorot_uniform and he_uniform inititalizers\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'], label=\"adam\", color='red')\n",
    "plt.plot(history_adagrad.history['loss'], label=\"adagrad\", color='blue')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <b>here</b> for the solution.\n",
    "\n",
    "<!-- Your answer is below:\n",
    "\n",
    "#Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Step 6: Train the Model\n",
    "history_adagrad = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)\n",
    "\n",
    "#Plotting training losses for glorot_uniform and he_uniform inititalizers\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'], label=\"adam\", color='red')\n",
    "plt.plot(history_adagrad.history['loss'], label=\"adagrad\", color='blue')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you for completing this lab!\n",
    "\n",
    "This notebook was created by [Aman Aggarwal](https://www.linkedin.com/in/aggarwal-aman/). I hope you found this lab interesting and educational. Feel free to contact me if you have any questions!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "## Change Log\n",
    "\n",
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2024-11-20  | 1.0  | Aman  |  Created the lab |\n",
    "<hr>\n",
    "-->\n",
    "## <h3 align=\"center\"> © IBM Corporation. All rights reserved. <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "3a07fb4049049613c9f3bf3a0aaeeac466433593dd808e2778bab531403fe8a9"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
